===================== Express =====================

const express = require('express');
const passport = require('passport');
const GoogleStrategy = require('passport-google-oauth20').Strategy;
const keys = require('./config/keys');


/* 
Most projects only use one app object(but they can use more)
the app object sets up configuration that listens for incomeing 
requests that are being routed from node to express and then route
those requests to different route handlers
*/
const app = express();


passport.use( // takes two arguments, object with client info and callbackURL, accesstoken
  new GoogleStrategy(
    {
      clientID: keys.googleClientID,
      clientSecret: keys.googleClientSecret,
      callbackURL: '/auth/google/callback'
    },
  (accessToken, refreshToken, profile, done) => { // this function is the callback 
    //that handles the info delivered by google to our server 
    console.log('accessToken: ', accessToken);
    console.log('refresh token: ', refreshToken);
    console.log('profile: ', profile)
  })
);

// Route Handler
// oauth flow managed by passport
// 'google' was given to us by stuff done in the background with passportjs, 
// thats why you never see it declared as and related back to new GoogleStrategy
// passportjs sees 'google' and automatically associates that with new GoogleStrategy 
// internally
// the second argument is an options object. scope specifys the type of access we want
// in this case we want access to the users profile and their email (other scopes listed in documentation)
app.get(
  '/auth/google',
  passport.authenticate("google", {
    scope: ["profile","email"] 
  })
);

// Route Handler
// visiting localhost:5000/auth/google will get profile from google and
// redirect to localhost:5000/auth/google/callback
// additonally there will be extra info in the returned url
// localhost:5000/auth/google/callback?code=bunch of random looking stuff
// this returned code is  turned into a profile by passportjs
app.get('/auth/google/callback', passport.authenticate('google'))


// look at underlying enviroment and check to see if it has
// a specific port it wants us to use - only works in production
// can include || that runs in development environment
// 5000 here refers to http://localhost:5000/
const PORT = process.env.PORT || 5000;

// listen to port
app.listen(PORT, () => console.log('listening')); // run from terminal with: node index.js




===============================================================

===================== Heroku =====================

tell heroku which version of node to use in your package.json file

  "engines": {
    "node": "11.3.0",
    "npm": "6.5.0"
    },

specify start script in package.json
replace 
"test": "echo \"Error: no test specified\" && exit 1"

with
"start": "node index.js"

create gitignore so that node dependencies aren't sent to heroku,
heroku will install the dependencies on its own

create file calle .gitignore
inside .gitignore put the following line of text:

node_modules 

this will ignore all files in the node modules folder

-------- in terminal --------

git init
git add .
git commit -m "comment"

make sure heroku CLI is installed (if not download installer - 
search for heroku CLI on google)

heroku --version
heroku login
heroku create

you should see two links, the first identifies the name of your app
to heroku, the second link is the deployment target. The deployment
target is a git repository we can push our local server to. When you
push your project to this repository, heroku will start it up automatically

git remote add heroku "link that you want to use"

example of what link looks like:
https://git.heroku.com/thawing-citadel-84114.git

git push heroku master

heroku open

// opens your project in a new browser window
// example of how the link to the project will look
https://thawing-citadel-84114.herokuapp.com/


deployment in the future

git status
git add .
git commit -m "changed greeting"
git push heroku master
heroku logs  // checks to see if anything went wrong - not a necessary step
heroku open

===============================================================

===================== Passport JS =====================
install passport js and a passport strategy
oauth20 is abbreviated for oauth2.0 (can't use . with npm)
the strategy instructs passport on how you want to authenticate the
user, we are using google but you can use facebook, twitter, etc

    npm install passport-google-oauth20@2 --save



Since the main goal of using http://localhost:5000/* was to show the redirect 
error a few lectures later,  we can do one of two things here:

1. Leave the authorized URI Redirect blank, since we will be fixing
 this later.

2. Enter http://localhost:5000/auth/google/callback now, since 
that is what it will be changed to in a later lecture.

===============================================================
===================== Google OAuth =====================
go to google to create oauth project 

console.developers.google.com

change to the newly created project
click credentials and create client id

Authorized JavaScript origins
http://localhost:5000/

Authorized redirect URIs
http://localhost:5000/auth/google/callback

you will then get a client id that looks like this:
711429008072-dlmio7cfm7ncqu28sg8j4ngivnii813h.apps.googleusercontent.com

and you will get a client secret

the client id identifies the application (public token). The client secret should
be kept private because it grants extra privileges (private token)

before pushing to github you will need to "hide" your client secret

make a config folder with keys.js file. put your client id and client secret in a module.exports object

module.exports = {
  googleClientId: 'CLIENT ID GOES HERE',
  googleClientSecret: 'CLIENT SECRET GOES HERE'
};

this allows you to export this info into other files.
Add keys.js to gitignore file do it doesn't get pushed to github


===============================================================
===================== Nodemon =====================
nodemon monitors for updates and displays in console
makes it so you don't have to restart server ever time you make a change
to your code

npm install --save nodemon


add script in package.json 

"server": "nodemon index.js"

use by running: npm run server

===============================================================
===================== MongoDB =====================

database made up of collections. example: users collection, payments collection, etc

within each collection each object can have the same or different properties. this
contrasts sql databases where each object in the collection would have to have
the same properties.

example of USERS Collection:
{ id: 1, name "anna" }, { id:2, name: "alex", age: 30 }, { id:3, weight: 170 }

======== Mongoose ========
mongoose js is a library that helps deal with MongoDB. It has a group of functions
called a -- Model Class -- that helps deal with a specific mongoDB collection. These 
functions may create new records, search records, etc.
a -- Model Instance -- is a group of functions that deal with a specific object
inside the collection

SRV connection String for this project
mongodb+srv://admin:<password>@emaily-zqhbm.mongodb.net/test?retryWrites=true

you have to replace <password> with the database users password.

mongoose requires that you define all the properties in your data records. 
This contrasts with mongoDB since mongoDB doesn't care if an object has 
different properties than another in a collection. Mongoose uses the term Schema
for this. A Schema is an object with all the properties and types you intend to
use for a collection.

const mongoose = require('mongoose');
const { Schema } = mongoose;

// set up list properties and types you will use with mongoose on a collection 
const userSchema = new Schema({
  googleId: String
});

// tell mongoose to create a new collection called users
// using two arguments here LOADS a SCHEMA into mongoose.
// using a single argument FETCHES a SCHEMA from mongoose.
mongoose.model('users', userSchema);


in passport.js require mongoose and the schema you want. You do this because
if you require mongoose and a schema in the index.js file it is possible that
mongoose can have an error during testing where it trys to require a schema 
in the same file multiple times it then conflicts saying you have multiple of 
the same schema and produces errors. To avoid this  require mongoose in 
the passport.js file.

const mongoose = require('mongoose');

//fetch schema from mongoose 
const User = mongoose.model('users');


// You can create a new Model Instance object in the Model Class Users so 
// it is available to save it to the database. the .save() function 
// persists the Model Instance to the database
// this is done in this app in passport.js in the callback function after 
// the googleStrategy in passport.use()

new User({ googleId: profile.Id }).save();




===============================================================
===================== Using Cookies =====================
cookies are limited to around 4kb of data. So you want to keep them small as possible.

when a record is made in the mongoDB database collection an id will be automatically
generated. We can use this id to authenticate user requests to the server in the
future. This id will be put into a cookie that the client sends with each http
request made to the server. The server will recognize the id sent in the cookie
as an authenticated user and send back the approrate data to the client.


--------passport.js
// attach id to user info for future authentication - creates cookie
passport.serializeUser((user, done)=>{
  // passport automatically makes user referenceable after entry is created in database
  done(null, user.id); // this is the autogenerated id created by mongoDB when googleId, 
                       // facebook, twitter, etc is sent to the database
});

// turn id into mongoose model instance, locates user in database
passport.deserializeUser((id, done)=>{
  User.findById(id)
    .then(user=> { // user is returned as part of promise when findById is invoked
      done(null, user);
    });
});

--------index.js
// make sure passport is aware it needs to use cookies to keep track of the
// signed in user. cookie-session library must be installed for this purpose

app.use(
  // cookieSession is a function that expects an object with two properties
  cookieSession({
    maxAge: 30*24*60*60*1000, // how long cookie can exist in browser in miliseconds (30 days)
    keys: [keys.cookieKey]  // key used to encrypt cookie
  })
)
app.use(passport.initialize());
app.use(passport.session());

/* 
app.use() is middleware that modifies the request before it is sent to route
handlers.
*/

/* 
cookieSession({
    maxAge: 30*24*60*60*1000, // how long cookie can exist in browser in miliseconds (30 days)
    keys: [keys.cookieKey]  // key used to encrypt cookie
  })

cookieSession extracts data from the request then passport pulls the user id out 
of that extracted data. When cookieSession extracts data from the request it puts 
it into the req.session object. Passport takes the data in req.session and gets the
user id out. 

  you can see this if you add the following route in auth Routes.js

  app.get('/api/current_user', (req, res) => {
    res.send(req.session);
  });

  cookieSession.js is a library recommened by express.js. There is also another library
  called express-session.js

  cookie-session library - you assign data to the cookie and cookieSession() takes that data
    and puts it in the req.session object. cookie-session stores the data directly in
    the cookie. So if you had a ton of data it would all be in the cookie


  express-session library - makes a store that contains an object with all the relevant
  data. It then creates an id that references that object. It puts the session id in the cookie
  and sends that.  So the only thing being sent is the session id.

  In other words you assign data to the cookie and expressSession() 
  takes that data and stores a reference to the session inside the cookie. It will put
  this as an id to a session. When the request comes back expressSession looks up the
  session id info from its session store. The cookie only contains the id of the session.
  The session store object can contain a lot of data. This keeps the cookie small

  if you want to use express-session you have to set up a session store

  */

===============================================================
===================== Production Environment =====================

you should create two sets of keys and databases for your app. The developer set is for testing, and 
messing around with stuff. The production set is for the deployed application which has
your actual users data and therefore not something you want to accidentally mess up.

to accomplish this you need to set up a different project in MongoDB and a different project
in your google developers account. 

the new project in mongoDB will have a different whitelisted ip address than the dev one. 
In this project we are using the heroku address so its ok to just whitelist all 
outside ip addresses. 

Your new project at console.developers.google.com should have a new set of credentials. 
For this project we are using the heroku webaddress as our "production" web address
you can get this with the terminal command

heroku open

https://thawing-citadel-84114.herokuapp.com/

you will need to also use
https://thawing-citadel-84114.herokuapp.com/auth/google/callback 
as the place where users get redirected

the keys.js file will be where the you determine which of these you want to use


when you deploy the server to heroku there is an existing environment variable called

NODE_ENV 

this variable tells whether you are running in a production environment


prod.js does get committed to heroku because you need the keys on heroku for deployment
to work properly in production. You will need to put in the keys as config vars on heroku
in the settings area for your app.
make sure to change the MONGO_URI to the user and password you set up for the 
production database

push changes to heroku before launching


===============================================================
===================== Stripe on Server =====================

npm install --save stripe


when you make requests to an express server, express does not automatically 
parse the payload sent to it. To do this we will install another module that
tells express how to parse the info and make it available to the rest of the 
application

===== body-parser =====

npm install --save body-parser

this is an express middleware so you have to wire it up to express with  
app.use() 

----index.js

const bodyParser = require('body-parser');

app.use(bodyParser.json());

===============================================================
===================== Handle Additonal Routes=====================
3 types of routes that our express server handles
1) routes specifically meant for express to handlers

2) routes not recognized by express where express needs to be told to get a specific
   file from client side (such as the /client/build/static/js/main.js file).
   In our index.js file express is told to check with client side first to 
   find a specific file. If this fails then express is told to use the index.html 
   file from the client. In other words, assime thats probably the file that can 
   reconcile the correct path. 
   Check to see if 'client/build' js file is needed. If not proceed to next step

3) routes not recognized by our backend - we will tell express that
   when this happens it should get the index.html file from client side of
   application to look for routes in there. In other words tell express to 
   assume the index.html file will have the correct route. 


---- index.js (server)
if(process.env.NODE_ENV === 'production'){
  // Express will serve up production assets
  // like our main.js file, or main.css file!
    app.use(express.static('client/build'));

  // Express will serve up the index.html file
  // if it doesn't recognize the route
  const path = require('path');
  app.get('*', (req,res) => {
    res.sendFile(path.resolve(__dirname, 'client', 'build', 'index.html'))
  })

}

===============================================================
===================== Build and Deployment =====================
you need to build your client side of the project before you can deploy it.

npm run build

3 options to deploy

1) we build the project and push it to heroku. We will need to build the project
  and push it ever time we make a change to the code

2) push everything to heroku and tell heroku to install all dependencies for 
   client side of project. The dependencies will only ever be used once.

3) Continuous integration
   third party server builds application. commit everything to git and push it 
   all to a server. the server can run tests on these files and then build the project 
   as a seperate branch and then push that build to heroku

make sure to add a script in server package.json to tell heroku to build client side of app

"heroku-postbuild": "NPM_CONFIG_PRODUCTION=false npm install --prefix client && npm run build --prefix client" 

we will be using option 2

-commit all files to git
-push to heroku
-heroku installs all server dependencies
-heroku runs script called 'heroku-posbuild' which can contain additional 
 instructions for heroku on how to set up and run our application

git status
git add .
git commit -m "comment"
git push heroku master
heroku logs
heroku open
===============================================================
===================== SubDocument Collection =====================
in a collection you can have something called a subDocument collection. For 
this project we have a collection of surveys. The survey is based on a schema from 
mongoose (surveySchema). Inside the surveySchema we have a property that is 
an array made up of a set of another type schema. In this case recipients

---- Survey.js

const recipientSchema = require('./Recipient');

const surveySchema = new Schema({
  title: String,
  body: String,
  subject: String,
  recipients: [RecipientSchema],
  yes: { type: Number, default: 0 },
  no: { type: Number, default: 0 }
});

this was done because of the potential of a large number of recipients. If we 
tried to associate our surveys as a subdocument collection of users, then each 
user would have multiple surverys. Each survey is sent out to potentially thousands
of recipients. MongoDB caps the amount of data alloted for a record at 4mb. If all 
the surveys were assigned as a subdocument under the user collection and the recipients 
were assigned under the surveys we would quickly run into a situation where the 
size of the record would be maxed out. Making a collection where each survey has a subdocumnet 
of recipients allows the user to have thousands of surveys and each survey to have thousands of 
recipients without the issue of a size limit on the record.


===================== Webhook with Mass Emails =====================
to send emails we are using sendgrid.com

when a link is included inside the email template we want sent to a set of 
email address sendgrid keeps track of those links. When clicked sendgrid 
collects info about the link the user wants to visit before sending the user 
to that destination. When this happens each link is customized for the user, so 
sendgrid knows who clicked the link. Sendgrid will send our server a message with 
info(email address) about the user that clicked on the link. This is called a webhook.

make sure to install the sendgrid module

npm install --save sendgrid

===============================================================
===================== REST Client (Testing Email) =====================
application that allows you to make api request to any arbitrary endpoint from 
any given server.

example: postman

this is complicated because we are using oauth

we will be instead testing the backend email portion with the axios module

we will then use the axios module to make a post request to our backend server 
from our react app manually
to do this we import axios into the client and make a post request in the 
browser console.

--- index.js (client)
import axios from 'axios';
window.axios = axios;

---react app console
const survey = { title: 'my title', subject: 'my subject', recipients: 'emailyouwanttotestwith@email.com', body: 'this is the email body' }

axios.post('/api/surveys', survey);

delete the axios stuff in the react index.js file after testing
import axios from 'axios'; //delete
window.axios = axios; //delete
===============================================================
===================== LocalTunnel =====================
online api service to handle webhooks for development purposes. 

you can set it to tell the emailer you are using (sendgrid in our case) to send 
a response email to the local server on your computer during development

npm install --save localtunnel

----in the root dir of the server create a new file called sendgrid_webhook.js .  
Add the following to that file:

    var localtunnel = require('localtunnel');
    localtunnel(5000, { subdomain: <YOUR_SUBDOMAIN> }, function(err, tunnel) {
      console.log('LT running')
    });


add start up script in package.json 

with specified port 5000, and special subdomain that you define "asxcnvwuwbc234543"

--- server package.json
"webhook": "forever sendgrid_webhook.js" 

also make sure you added it to start up along with the server and client

"dev": "concurrently \"npm run server\" \"npm run client\" \"npm run webhook\"",

when you do npm run dev and start up the dev server you also need to go to
your emailer service (sendgrid.com) 

---sendgrid.com
go to settings 
mail settings
event notification

add in your custom localTunnel http address (you can find it in the terminal 
while your dev server is running). You then add the route you want sendgrid to send 
the information to through the local tunnel

subdomain example: https://asxcnvwuwbc234543.localtunnel.me
route: /api/surveys/webhooks

combine them and paste into

HTTP Post Url
https://asxcnvwuwbc234543.localtunnel.me/api/surveys/webhooks

you van then click "test your integration" to test 

check off the "clicked" box because we want to know when people click our links from 
the emails that people receive from sendgrid.


WHEN YOU DEPLOY YOU NEED TO CHANVE YOUR HTTP POST URL
because you can only have one at a time instead of one for dev and one for prod.

===============================================================
===================== Path Parser =====================

npm install --save path-parser@2.0.2

===============================================================
===================== lodash =====================


